"use strict";(globalThis.webpackChunkeigenbytes=globalThis.webpackChunkeigenbytes||[]).push([[1406],{818(e,n,i){i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"technical-papers/continuous-authentication/03 system-architecture","title":"System Architecture","description":"Introduction","source":"@site/docs/publications/technical-papers/continuous-authentication/03 system-architecture.md","sourceDirName":"technical-papers/continuous-authentication","slug":"/technical-papers/continuous-authentication/03 system-architecture","permalink":"/publications/technical-papers/continuous-authentication/03 system-architecture","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"System Architecture","section":"Continuous Authentication","type":"Paper Section"},"sidebar":"sidebar","previous":{"title":"Problem Context","permalink":"/publications/technical-papers/continuous-authentication/02 problem-context"},"next":{"title":"Biometric Models - Part 1: Physiological","permalink":"/publications/technical-papers/continuous-authentication/04 biometric-models-part1"}}');var s=i(4848),r=i(8453);const a={title:"System Architecture",section:"Continuous Authentication",type:"Paper Section"},o="System Architecture & Overview",c={},l=[{value:"Introduction",id:"introduction",level:2},{value:"High-Level Architecture",id:"high-level-architecture",level:2},{value:"Core System Modules",id:"core-system-modules",level:2},{value:"1. Data Acquisition Module",id:"1-data-acquisition-module",level:3},{value:"2. Preprocessing Module",id:"2-preprocessing-module",level:3},{value:"3. Matcher Modules",id:"3-matcher-modules",level:3},{value:"Face Matcher",id:"face-matcher",level:4},{value:"Voice Matcher",id:"voice-matcher",level:4},{value:"Keystroke Dynamics Matcher",id:"keystroke-dynamics-matcher",level:4},{value:"Activity Recognition Matcher",id:"activity-recognition-matcher",level:4},{value:"4. Feature Fusion Module",id:"4-feature-fusion-module",level:3},{value:"5. Risk Classification Module",id:"5-risk-classification-module",level:3},{value:"6. Decision &amp; Feedback Module",id:"6-decision--feedback-module",level:3},{value:"Complete Data Flow",id:"complete-data-flow",level:2},{value:"User Experience Flow",id:"user-experience-flow",level:2},{value:"Web Application Workflow",id:"web-application-workflow",level:3},{value:"System Integration Points",id:"system-integration-points",level:2},{value:"Module Interaction Overview",id:"module-interaction-overview",level:3},{value:"Unique Aspects of the Solution",id:"unique-aspects-of-the-solution",level:2},{value:"1. Adaptive Authentication",id:"1-adaptive-authentication",level:3},{value:"2. Minimal User Disruption",id:"2-minimal-user-disruption",level:3},{value:"3. Escalating Verification",id:"3-escalating-verification",level:3},{value:"4. Application-Agnostic Design",id:"4-application-agnostic-design",level:3},{value:"5. Multi-Layer Security",id:"5-multi-layer-security",level:3},{value:"System Requirements",id:"system-requirements",level:2},{value:"Hardware Requirements",id:"hardware-requirements",level:3},{value:"Software Requirements",id:"software-requirements",level:3},{value:"Performance Targets",id:"performance-targets",level:3},{value:"Security Considerations",id:"security-considerations",level:2},{value:"Data Protection",id:"data-protection",level:3},{value:"Attack Resistance",id:"attack-resistance",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"system-architecture--overview",children:"System Architecture & Overview"})}),"\n",(0,s.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(n.p,{children:"The proposed continuous authentication system introduces a novel approach that integrates keystroke dynamics and human activity recognition data from mobile and IoT devices into a unified risk assessment framework. Unlike traditional authentication that verifies identity only at login, this system continuously monitors user behavior throughout the session and dynamically escalates verification requirements based on assessed risk levels."}),"\n",(0,s.jsx)(n.h2,{id:"high-level-architecture",children:"High-Level Architecture"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:'flowchart TB\n    subgraph Input["Data Acquisition Layer"]\n        A1[Facial Camera]\n        A2[Microphone]\n        A3[Keyboard/Mouse]\n        A4[Mobile Sensors]\n        A5[Contextual Data]\n    end\n    \n    subgraph Processing["Preprocessing Layer"]\n        B1[Image Normalization]\n        B2[Audio Feature Extraction]\n        B3[Keystroke Pattern Analysis]\n        B4[Activity Feature Engineering]\n        B5[Context Aggregation]\n    end\n    \n    subgraph Models["Authentication Models"]\n        C1[Face Matcher]\n        C2[Voice Matcher]\n        C3[Keystroke Matcher]\n        C4[Activity Recognition]\n    end\n    \n    subgraph Decision["Risk Assessment & Decision"]\n        D1[Feature Fusion]\n        D2[Random Forest Classifier]\n        D3[Risk Level Output]\n    end\n    \n    subgraph Action["Action Layer"]\n        E1[Low Risk: Continue]\n        E2[Medium Risk: Voice Check]\n        E3[High Risk: Face Check]\n        E4[Deny Access]\n    end\n    \n    A1 --\x3e B1 --\x3e C1\n    A2 --\x3e B2 --\x3e C2\n    A3 --\x3e B3 --\x3e C3\n    A4 --\x3e B4 --\x3e C4\n    A5 --\x3e B5\n    \n    C3 --\x3e D1\n    C4 --\x3e D1\n    B5 --\x3e D1\n    \n    D1 --\x3e D2\n    D2 --\x3e D3\n    \n    D3 --\x3e|Low| E1\n    D3 --\x3e|Medium| E2\n    D3 --\x3e|High| E3\n    \n    E2 --\x3e|Pass| E1\n    E2 --\x3e|Fail| E3\n    E3 --\x3e|Pass| E1\n    E3 --\x3e|Fail| E4\n'})}),"\n",(0,s.jsx)(n.h2,{id:"core-system-modules",children:"Core System Modules"}),"\n",(0,s.jsx)(n.h3,{id:"1-data-acquisition-module",children:"1. Data Acquisition Module"}),"\n",(0,s.jsx)(n.p,{children:"The foundation of the continuous authentication system, responsible for collecting multi-modal biometric and contextual data."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Biometric Data Sources:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Facial Data"}),": Captured via webcam/device camera"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Voice Data"}),": Recorded through microphone during natural interaction"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Keystroke Data"}),": Monitoring typing patterns (hold time, flight time)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Activity Data"}),": Mobile sensors (accelerometer, gyroscope, GPS)"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Contextual Data Sources:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Device type and fingerprint"}),"\n",(0,s.jsx)(n.li,{children:"IP address and geolocation"}),"\n",(0,s.jsx)(n.li,{children:"Session duration and login time"}),"\n",(0,s.jsx)(n.li,{children:"Network conditions"}),"\n",(0,s.jsx)(n.li,{children:"Application usage patterns"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"2-preprocessing-module",children:"2. Preprocessing Module"}),"\n",(0,s.jsx)(n.p,{children:"Transforms raw data into standardized formats suitable for machine learning models."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:"graph LR\n    subgraph Facial\n        A1[Raw Image] --\x3e A2[Resize 160x160]\n        A2 --\x3e A3[Normalize Pixels]\n        A3 --\x3e A4[Face Detection]\n    end\n    \n    subgraph Voice\n        B1[Audio Stream] --\x3e B2[Noise Reduction]\n        B2 --\x3e B3[MFCC Extraction]\n        B3 --\x3e B4[Mel Spectrogram]\n    end\n    \n    subgraph Keystroke\n        C1[Key Events] --\x3e C2[Calculate Timings]\n        C2 --\x3e C3[Hold & Flight Times]\n        C3 --\x3e C4[Normalize Features]\n    end\n    \n    subgraph Activity\n        D1[Sensor Data] --\x3e D2[Windowing]\n        D2 --\x3e D3[Feature Engineering]\n        D3 --\x3e D4[Normalization]\n    end\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Processing Steps by Modality:"})}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Modality"}),(0,s.jsx)(n.th,{children:"Input"}),(0,s.jsx)(n.th,{children:"Processing"}),(0,s.jsx)(n.th,{children:"Output"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Face"}),(0,s.jsx)(n.td,{children:"Raw image frames"}),(0,s.jsx)(n.td,{children:"Resize, normalize, detect faces"}),(0,s.jsx)(n.td,{children:"160x160x3 normalized arrays"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Voice"}),(0,s.jsx)(n.td,{children:"Audio waveform"}),(0,s.jsx)(n.td,{children:"Noise reduction, MFCC extraction"}),(0,s.jsx)(n.td,{children:"Mel spectrograms (128x64)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Keystroke"}),(0,s.jsx)(n.td,{children:"Key press/release events"}),(0,s.jsx)(n.td,{children:"Timing calculation, normalization"}),(0,s.jsx)(n.td,{children:"Hold/flight time vectors"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Activity"}),(0,s.jsx)(n.td,{children:"Accelerometer/gyroscope"}),(0,s.jsx)(n.td,{children:"Windowing, feature extraction"}),(0,s.jsx)(n.td,{children:"561-dimensional feature vectors"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"3-matcher-modules",children:"3. Matcher Modules"}),"\n",(0,s.jsx)(n.p,{children:"Specialized deep learning models for each biometric modality."}),"\n",(0,s.jsx)(n.h4,{id:"face-matcher",children:"Face Matcher"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Architecture"}),": MobileNetV2 with triplet loss"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Function"}),": Generates 512-dimensional facial embeddings"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Comparison"}),": Euclidean distance between embeddings"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Threshold"}),": Optimized at 0.5392"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"voice-matcher",children:"Voice Matcher"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Architecture"}),": GRU with attention mechanism"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Function"}),": Creates speaker-specific voiceprints"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Input"}),": Mel spectrograms (128x64)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Output"}),": Speaker classification probabilities"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"keystroke-dynamics-matcher",children:"Keystroke Dynamics Matcher"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Architecture"}),": Bi-directional LSTM"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Function"}),": Analyzes typing rhythm and timing patterns"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Features"}),": Hold time, flight time, digraph analysis"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Output"}),": User-specific typing embeddings"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"activity-recognition-matcher",children:"Activity Recognition Matcher"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Architecture"}),": CNN-GRU hybrid"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Function"}),": Classifies human activities from sensor data"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Activities"}),": Walking, sitting, standing, running, etc."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Dataset"}),": UCI HAR (Human Activity Recognition)"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"4-feature-fusion-module",children:"4. Feature Fusion Module"}),"\n",(0,s.jsx)(n.p,{children:"Integrates outputs from keystroke dynamics and activity recognition for comprehensive behavioral analysis."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:"graph TB\n    A[Keystroke Features] --\x3e C[Feature Concatenation]\n    B[Activity Features] --\x3e C\n    D[Contextual Features] --\x3e C\n    C --\x3e E[Unified Feature Vector]\n    E --\x3e F[Normalization]\n    F --\x3e G[To Risk Classifier]\n    \n    style E fill:#a8dadc\n    style G fill:#457b9d\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Fusion Strategy:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Level"}),": Feature-level fusion (early fusion)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Method"}),": Concatenation of normalized feature vectors"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Advantage"}),": Captures interactions between behavioral modalities"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Output"}),": Single unified representation for risk assessment"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"5-risk-classification-module",children:"5. Risk Classification Module"}),"\n",(0,s.jsx)(n.p,{children:"A Random Forest classifier that categorizes authentication attempts into three risk levels."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Input Features:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Keystroke dynamics embeddings"}),"\n",(0,s.jsx)(n.li,{children:"Human activity patterns"}),"\n",(0,s.jsx)(n.li,{children:"Contextual parameters (IP reputation, geolocation, session data)"}),"\n",(0,s.jsx)(n.li,{children:"Login anomalies (time, frequency, duration)"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Risk Levels:"})}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Risk Level"}),(0,s.jsx)(n.th,{children:"Criteria"}),(0,s.jsx)(n.th,{children:"Action Required"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Low"}),(0,s.jsx)(n.td,{children:"Behavior matches historical patterns"}),(0,s.jsx)(n.td,{children:"Continue session seamlessly"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Medium"}),(0,s.jsx)(n.td,{children:"Minor deviations detected"}),(0,s.jsx)(n.td,{children:"Trigger voice verification"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"High"}),(0,s.jsx)(n.td,{children:"Significant anomalies or failed voice check"}),(0,s.jsx)(n.td,{children:"Require face verification"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"6-decision--feedback-module",children:"6. Decision & Feedback Module"}),"\n",(0,s.jsx)(n.p,{children:"Manages the adaptive authentication flow based on risk assessment."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:"stateDiagram-v2\n    [*] --\x3e RiskAssessment\n    RiskAssessment --\x3e LowRisk: Normal Behavior\n    RiskAssessment --\x3e MediumRisk: Minor Deviation\n    RiskAssessment --\x3e HighRisk: Major Anomaly\n    \n    LowRisk --\x3e ContinueSession\n    ContinueSession --\x3e [*]\n    \n    MediumRisk --\x3e VoiceCheck\n    VoiceCheck --\x3e ContinueSession: Pass\n    VoiceCheck --\x3e FaceCheck: Fail\n    \n    HighRisk --\x3e FaceCheck\n    FaceCheck --\x3e ContinueSession: Pass\n    FaceCheck --\x3e DenyAccess: Fail\n    \n    DenyAccess --\x3e [*]\n"})}),"\n",(0,s.jsx)(n.h2,{id:"complete-data-flow",children:"Complete Data Flow"}),"\n",(0,s.jsx)(n.p,{children:"The system operates in a continuous loop throughout the user session:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:"sequenceDiagram\n    participant U as User\n    participant S as System\n    participant K as Keystroke Module\n    participant A as Activity Module\n    participant R as Risk Classifier\n    participant V as Voice Matcher\n    participant F as Face Matcher\n    \n    U->>S: Login (Initial Auth)\n    S->>U: Session Started\n    \n    loop Continuous Monitoring\n        U->>K: Typing Activity\n        U->>A: Physical Movement\n        K->>R: Keystroke Features\n        A->>R: Activity Features\n        S->>R: Contextual Data\n        \n        R->>R: Classify Risk\n        \n        alt Low Risk\n            R->>U: Continue Session\n        else Medium Risk\n            R->>V: Trigger Voice Check\n            U->>V: Provide Voice Sample\n            alt Voice Match\n                V->>U: Continue Session\n            else Voice Fail\n                V->>F: Escalate to Face Check\n                U->>F: Provide Face Image\n                alt Face Match\n                    F->>U: Continue Session\n                else Face Fail\n                    F->>U: Terminate Session\n                end\n            end\n        else High Risk\n            R->>F: Trigger Face Check\n            U->>F: Provide Face Image\n            alt Face Match\n                F->>U: Continue Session\n            else Face Fail\n                F->>U: Terminate Session\n            end\n        end\n    end\n"})}),"\n",(0,s.jsx)(n.h2,{id:"user-experience-flow",children:"User Experience Flow"}),"\n",(0,s.jsx)(n.h3,{id:"web-application-workflow",children:"Web Application Workflow"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:"flowchart TD\n    Start([User Accesses System]) --\x3e Register{Registered?}\n    Register --\x3e|No| Reg[Registration Process]\n    Register --\x3e|Yes| Login[Login: Email + Password]\n    \n    Reg --\x3e EnrollBio[Biometric Enrollment]\n    EnrollBio --\x3e KS[Type Sentence 10x]\n    KS --\x3e Store[Store Baseline]\n    Store --\x3e Login\n    \n    Login --\x3e Auth{Credentials Valid?}\n    Auth --\x3e|No| Login\n    Auth --\x3e|Yes| Session[Session Started]\n    \n    Session --\x3e Monitor[Continuous Monitoring]\n    Monitor --\x3e Collect[Collect Keystroke + Activity]\n    Collect --\x3e Compare[Compare to Baseline]\n    Compare --\x3e Risk{Risk Level?}\n    \n    Risk --\x3e|Low| Continue[Continue Working]\n    Risk --\x3e|Medium| Voice[Voice Verification]\n    Risk --\x3e|High| Face[Face Verification]\n    \n    Voice --\x3e|Pass| Continue\n    Voice --\x3e|Fail| Face\n    Face --\x3e|Pass| Continue\n    Face --\x3e|Fail| Deny[Terminate Session]\n    \n    Continue --\x3e Monitor\n    Deny --\x3e End([Session Ended])\n"})}),"\n",(0,s.jsx)(n.h2,{id:"system-integration-points",children:"System Integration Points"}),"\n",(0,s.jsx)(n.h3,{id:"module-interaction-overview",children:"Module Interaction Overview"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:'graph TB\n    subgraph Frontend["User Interface Layer"]\n        UI1[Web Interface]\n        UI2[Camera Access]\n        UI3[Microphone Access]\n        UI4[Keyboard Listener]\n    end\n    \n    subgraph Backend["Processing Backend"]\n        BE1[Authentication API]\n        BE2[Model Inference Engine]\n        BE3[Risk Evaluation Service]\n    end\n    \n    subgraph Storage["Data Storage"]\n        DB1[User Profiles]\n        DB2[Biometric Templates]\n        DB3[Session Logs]\n        DB4[Audit Trails]\n    end\n    \n    subgraph Models["ML Model Services"]\n        ML1[Face Model Service]\n        ML2[Voice Model Service]\n        ML3[Keystroke Model Service]\n        ML4[Activity Model Service]\n        ML5[Risk Classifier Service]\n    end\n    \n    UI1 --\x3e BE1\n    UI2 --\x3e ML1\n    UI3 --\x3e ML2\n    UI4 --\x3e ML3\n    \n    BE1 --\x3e BE2\n    BE2 --\x3e ML1\n    BE2 --\x3e ML2\n    BE2 --\x3e ML3\n    BE2 --\x3e ML4\n    \n    BE2 --\x3e BE3\n    BE3 --\x3e ML5\n    \n    BE1 --\x3e DB1\n    BE2 --\x3e DB2\n    BE3 --\x3e DB3\n    BE3 --\x3e DB4\n'})}),"\n",(0,s.jsx)(n.h2,{id:"unique-aspects-of-the-solution",children:"Unique Aspects of the Solution"}),"\n",(0,s.jsx)(n.h3,{id:"1-adaptive-authentication",children:"1. Adaptive Authentication"}),"\n",(0,s.jsx)(n.p,{children:"The system learns and evolves with user behavior over time, reducing false positives and creating a personalized security profile."}),"\n",(0,s.jsx)(n.h3,{id:"2-minimal-user-disruption",children:"2. Minimal User Disruption"}),"\n",(0,s.jsx)(n.p,{children:"By using passive behavioral monitoring (keystroke and activity patterns), the system performs continuous checks without requiring active user participation unless risk is detected."}),"\n",(0,s.jsx)(n.h3,{id:"3-escalating-verification",children:"3. Escalating Verification"}),"\n",(0,s.jsx)(n.p,{children:"Rather than applying maximum security at all times, the system intelligently escalates authentication requirements based on detected risk, balancing security with usability."}),"\n",(0,s.jsx)(n.h3,{id:"4-application-agnostic-design",children:"4. Application-Agnostic Design"}),"\n",(0,s.jsx)(n.p,{children:"The modular architecture allows the system to be integrated into various platforms (web, mobile, desktop) without modification to core components."}),"\n",(0,s.jsx)(n.h3,{id:"5-multi-layer-security",children:"5. Multi-Layer Security"}),"\n",(0,s.jsx)(n.p,{children:"Combining behavioral biometrics (passive) with physiological biometrics (active) creates multiple layers of defense against sophisticated attacks."}),"\n",(0,s.jsx)(n.h2,{id:"system-requirements",children:"System Requirements"}),"\n",(0,s.jsx)(n.h3,{id:"hardware-requirements",children:"Hardware Requirements"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Camera"}),": For facial recognition (minimum 720p)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Microphone"}),": For voice authentication (standard quality)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Input Devices"}),": Keyboard/mouse for keystroke dynamics"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Mobile Sensors"}),": Accelerometer, gyroscope (for mobile deployment)"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"software-requirements",children:"Software Requirements"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Deep Learning Frameworks"}),": TensorFlow 2.x or PyTorch 1.x"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Computer Vision"}),": OpenCV 4.x"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Python"}),": 3.8 or higher"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Database"}),": SQLite (development) / PostgreSQL (production)"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"performance-targets",children:"Performance Targets"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Latency"}),": Under 200ms for risk assessment"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Accuracy"}),": Above 85% for all biometric modalities"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"False Acceptance Rate"}),": Below 5%"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"False Rejection Rate"}),": Below 10%"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"security-considerations",children:"Security Considerations"}),"\n",(0,s.jsx)(n.h3,{id:"data-protection",children:"Data Protection"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"All biometric data encrypted at rest and in transit"}),"\n",(0,s.jsx)(n.li,{children:"User embeddings stored instead of raw biometric data"}),"\n",(0,s.jsx)(n.li,{children:"Compliance with GDPR and relevant privacy regulations"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"attack-resistance",children:"Attack Resistance"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Protection against replay attacks through liveness detection"}),"\n",(0,s.jsx)(n.li,{children:"Spoofing resistance via multi-modal verification"}),"\n",(0,s.jsx)(n.li,{children:"Session hijacking prevention through continuous monitoring"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453(e,n,i){i.d(n,{R:()=>a,x:()=>o});var t=i(6540);const s={},r=t.createContext(s);function a(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);